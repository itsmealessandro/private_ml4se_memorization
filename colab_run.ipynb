{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36d78833",
   "metadata": {},
   "source": [
    "# LLM Memorization Project — Colab Runner\n",
    "\n",
    "Questo notebook è un template riutilizzabile per far girare il progetto su Google Colab.\n",
    "\n",
    "Supporta 2 modalità:\n",
    "- **Git clone** del repo\n",
    "- **Upload di uno ZIP** del progetto e unzip\n",
    "\n",
    "Nota: per evitare di scaricare l’intero split del dataset su Colab, useremo `--streaming` (aggiunto in `run_experiment.py`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0c36a5",
   "metadata": {},
   "source": [
    "## 1) Verifica runtime Colab (Python/GPU)\n",
    "Controlla subito versione Python, GPU e spazio disco."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6aedf7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, shutil, platform, json, time, pathlib\n",
    "\n",
    "print(\"Python:\", sys.version)\n",
    "print(\"Platform:\", platform.platform())\n",
    "print(\"Disk usage (/content):\", shutil.disk_usage(\"/content\"))\n",
    "\n",
    "try:\n",
    "    import torch\n",
    "    print(\"torch:\", torch.__version__)\n",
    "    print(\"CUDA available:\", torch.cuda.is_available())\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"CUDA device:\", torch.cuda.get_device_name(0))\n",
    "except Exception as e:\n",
    "    print(\"Torch not available yet:\", repr(e))\n",
    "\n",
    "# nvidia-smi (se presente)\n",
    "ret = os.system(\"nvidia-smi -L\")\n",
    "if ret != 0:\n",
    "    print(\"nvidia-smi non disponibile (ok se runtime CPU)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084a1da1",
   "metadata": {},
   "source": [
    "## 2) Installazione dipendenze (pip/apt)\n",
    "Installazione via `requirements.txt`. Impostiamo anche la cache Hugging Face in `/content/hf` per evitare problemi di spazio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fb7074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cache HF/Transformers\n",
    "os.environ[\"HF_HOME\"] = \"/content/hf\"\n",
    "os.environ[\"TRANSFORMERS_CACHE\"] = \"/content/hf/transformers\"\n",
    "pathlib.Path(os.environ[\"HF_HOME\"]).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# (Opzionale) install deps di sistema. Di solito non serve per questo progetto.\n",
    "# !apt-get update -qq\n",
    "\n",
    "CLEAN_REINSTALL = False\n",
    "if CLEAN_REINSTALL:\n",
    "    !pip -q uninstall -y transformers datasets accelerate datasketches tqdm numpy\n",
    "\n",
    "!pip -q install -U pip\n",
    "\n",
    "# Se hai già caricato/clonato il repo, esegui questo dopo aver fatto %cd nel repo\n",
    "# (qui lo lasciamo, verrà rieseguito più sotto quando sappiamo la cartella)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3151aec7",
   "metadata": {},
   "source": [
    "## 3) Clona/aggiorna repository (opzionale)\n",
    "Scegli **UNA** modalità:\n",
    "- `METHOD = \"git\"` se hai un repo pubblico/privato accessibile\n",
    "- `METHOD = \"zip\"` se vuoi caricare un archivio del progetto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c945f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scegli: \"git\" oppure \"zip\"\n",
    "METHOD = \"zip\"\n",
    "\n",
    "REPO_URL = \"https://github.com/<user>/<repo>.git\"  # TODO: se usi git\n",
    "REPO_DIRNAME = \"llm_memorization_project\"  # cartella attesa dopo clone/unzip\n",
    "\n",
    "if METHOD == \"git\":\n",
    "    %cd /content\n",
    "    if not pathlib.Path(REPO_DIRNAME).exists():\n",
    "        !git clone {REPO_URL} {REPO_DIRNAME}\n",
    "    %cd /content/{REPO_DIRNAME}\n",
    "\n",
    "elif METHOD == \"zip\":\n",
    "    from google.colab import files\n",
    "    %cd /content\n",
    "    uploaded = files.upload()  # carica es. llm_memorization_project.zip\n",
    "    if not uploaded:\n",
    "        raise RuntimeError(\"Nessun file caricato\")\n",
    "\n",
    "    zip_name = next(iter(uploaded.keys()))\n",
    "    print(\"Uploaded:\", zip_name)\n",
    "\n",
    "    # Estrai in /content\n",
    "    !unzip -q -o {zip_name} -d /content\n",
    "\n",
    "    # Prova a trovare la cartella del repo (se lo zip contiene una top-folder)\n",
    "    candidates = [p for p in pathlib.Path(\"/content\").glob(\"**/run_experiment.py\") if \"site-packages\" not in str(p)]\n",
    "    if not candidates:\n",
    "        raise RuntimeError(\"Non trovo run_experiment.py dopo unzip; controlla la struttura dello ZIP\")\n",
    "\n",
    "    repo_root = candidates[0].parent\n",
    "    # Se run_experiment.py è dentro una sottocartella, risali finché trovi requirements.txt\n",
    "    while repo_root != repo_root.parent and not (repo_root / \"requirements.txt\").exists():\n",
    "        repo_root = repo_root.parent\n",
    "\n",
    "    print(\"Repo root:\", repo_root)\n",
    "    %cd {repo_root}\n",
    "else:\n",
    "    raise ValueError(\"METHOD deve essere 'git' o 'zip'\")\n",
    "\n",
    "# Sanity check\n",
    "for needed in [\"run_experiment.py\", \"requirements.txt\", \"prompts/code_gen_prompt.txt\"]:\n",
    "    assert pathlib.Path(needed).exists(), f\"Missing {needed}\"\n",
    "print(\"Repo OK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93716166",
   "metadata": {},
   "source": [
    "## 4) Mount Google Drive e gestione percorsi\n",
    "Se vuoi persistire i risultati anche dopo che Colab si resetta, monta Drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41bcb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "MOUNT_DRIVE = False\n",
    "DRIVE_BASE = \"/content/drive/MyDrive\"\n",
    "\n",
    "if MOUNT_DRIVE:\n",
    "    from google.colab import drive\n",
    "    drive.mount(\"/content/drive\")\n",
    "\n",
    "BASE_DIR = pathlib.Path.cwd()\n",
    "OUT_DIR = BASE_DIR / \"reports\"\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if MOUNT_DRIVE:\n",
    "    DRIVE_OUT_DIR = pathlib.Path(DRIVE_BASE) / \"llm_memorization_project_outputs\"\n",
    "    DRIVE_OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    print(\"Drive output dir:\", DRIVE_OUT_DIR)\n",
    "\n",
    "print(\"BASE_DIR:\", BASE_DIR)\n",
    "print(\"OUT_DIR:\", OUT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4daee760",
   "metadata": {},
   "source": [
    "## 5) Upload dataset/file locali (fallback senza Drive)\n",
    "Di solito NON serve: il dataset arriva da Hugging Face via `datasets`. Usa questa cella solo se devi caricare file extra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00598958",
   "metadata": {},
   "outputs": [],
   "source": [
    "UPLOAD_EXTRA_FILES = False\n",
    "\n",
    "if UPLOAD_EXTRA_FILES:\n",
    "    from google.colab import files\n",
    "    uploaded = files.upload()\n",
    "    print(\"Uploaded:\", list(uploaded.keys()))\n",
    "\n",
    "    # Se carichi zip/tar di dati, estraili qui\n",
    "    for name in uploaded.keys():\n",
    "        if name.endswith(\".zip\"):\n",
    "            !unzip -q -o {name} -d /content/data_upload\n",
    "    if pathlib.Path(\"/content/data_upload\").exists():\n",
    "        total_bytes = sum(p.stat().st_size for p in pathlib.Path(\"/content/data_upload\").rglob(\"*\") if p.is_file())\n",
    "        print(\"/content/data_upload size (bytes):\", total_bytes)\n",
    "else:\n",
    "    print(\"Skipping\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5a3b89",
   "metadata": {},
   "source": [
    "## 6) Configurazione variabili (path, hyperparam, flags)\n",
    "Qui imposti modello, numero campioni, token, seed e flags Colab-friendly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50100e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config centrale\n",
    "CFG = {\n",
    "    \"dataset\": \"Nan-Do/code-search-net-python\",\n",
    "    \"split\": \"train\",\n",
    "    \"n\": 5,  # tienilo basso per un primo run su Colab\n",
    "    \"seed\": 42,\n",
    "    \"model\": \"Qwen/Qwen2-0.5B-Instruct\",\n",
    "    \"prompt\": \"prompts/code_gen_prompt.txt\",\n",
    "    \"max_new_tokens\": 256,\n",
    "    \"perturb\": True,\n",
    "    \"streaming\": True,\n",
    "    \"streaming_buffer_size\": 10_000,\n",
    "    \"output_name\": \"results_colab.json\",\n",
    "}\n",
    "\n",
    "# Salva config per riproducibilità\n",
    "(OUT_DIR / \"colab_cfg.json\").write_text(json.dumps(CFG, indent=2), encoding=\"utf-8\")\n",
    "print(\"Saved config:\", OUT_DIR / \"colab_cfg.json\")\n",
    "print(json.dumps(CFG, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e44249",
   "metadata": {},
   "source": [
    "## 2b) Installa requirements del progetto\n",
    "Esegui questa cella DOPO aver clonato/unzippato ed essere dentro la cartella del repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b70904f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -q install -r requirements.txt\n",
    "\n",
    "# Versioni per riproducibilità\n",
    "import datasets, transformers\n",
    "print(\"datasets:\", datasets.__version__)\n",
    "print(\"transformers:\", transformers.__version__)\n",
    "print(\"accelerate:\", __import__(\"accelerate\").__version__)\n",
    "print(\"datasketches:\", __import__(\"datasketches\").__version__)\n",
    "print(\"numpy:\", __import__(\"numpy\").__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3fc36b3",
   "metadata": {},
   "source": [
    "## 7) Esecuzione pipeline/script principali\n",
    "Esegue `run_experiment.py` e salva risultati in `reports/analysis_<timestamp>/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbd180f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Costruisci command line\n",
    "cmd = [\n",
    "    \"python\", \"run_experiment.py\",\n",
    "    \"--dataset\", CFG[\"dataset\"],\n",
    "    \"--split\", CFG[\"split\"],\n",
    "    \"--n\", str(CFG[\"n\"]),\n",
    "    \"--seed\", str(CFG[\"seed\"]),\n",
    "    \"--model\", CFG[\"model\"],\n",
    "    \"--prompt\", CFG[\"prompt\"],\n",
    "    \"--max-new-tokens\", str(CFG[\"max_new_tokens\"]),\n",
    "    \"--output\", CFG[\"output_name\"],\n",
    "]\n",
    "\n",
    "# BooleanOptionalAction: usa --perturb / --no-perturb\n",
    "cmd.append(\"--perturb\" if CFG[\"perturb\"] else \"--no-perturb\")\n",
    "cmd.append(\"--streaming\" if CFG[\"streaming\"] else \"--no-streaming\")\n",
    "cmd += [\"--streaming-buffer-size\", str(CFG[\"streaming_buffer_size\"])]\n",
    "\n",
    "print(\"Running:\", \" \".join(cmd))\n",
    "\n",
    "# Log su file (utile per debug)\n",
    "log_path = OUT_DIR / \"colab_run.log\"\n",
    "\n",
    "# Esegui con tee: stdout+stderr -> notebook e file\n",
    "import subprocess\n",
    "with open(log_path, \"w\", encoding=\"utf-8\") as lf:\n",
    "    p = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "    for line in p.stdout:\n",
    "        print(line, end=\"\")\n",
    "        lf.write(line)\n",
    "    rc = p.wait()\n",
    "\n",
    "print(\"Exit code:\", rc)\n",
    "print(\"Log:\", log_path)\n",
    "if rc != 0:\n",
    "    raise RuntimeError(f\"run_experiment.py failed with code {rc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314f613f",
   "metadata": {},
   "source": [
    "## 8) Logging e output (stdout + file)\n",
    "Trova l’ultima cartella `reports/analysis_*` e mostra i file prodotti."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a621f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def latest_analysis_dir(reports_dir: pathlib.Path) -> pathlib.Path | None:\n",
    "    if not reports_dir.exists():\n",
    "        return None\n",
    "    dirs = [p for p in reports_dir.glob(\"analysis_*\") if p.is_dir()]\n",
    "    if not dirs:\n",
    "        return None\n",
    "    return max(dirs, key=lambda p: p.stat().st_mtime)\n",
    "\n",
    "latest = latest_analysis_dir(OUT_DIR)\n",
    "print(\"Latest analysis dir:\", latest)\n",
    "\n",
    "if latest:\n",
    "    files = sorted([p for p in latest.rglob(\"*\") if p.is_file()])\n",
    "    for p in files:\n",
    "        print(\"-\", p.relative_to(BASE_DIR), f\"({p.stat().st_size} bytes)\")\n",
    "\n",
    "    report_md = latest / \"REPORT.md\"\n",
    "    results_json = latest / CFG[\"output_name\"]\n",
    "    print(\"\\nREPORT.md:\", report_md)\n",
    "    print(\"results.json:\", results_json)\n",
    "else:\n",
    "    print(\"Nessuna cartella analysis_* trovata\")\n",
    "\n",
    "# Mostra ultime righe log\n",
    "if log_path.exists():\n",
    "    print(\"\\n--- Tail log ---\")\n",
    "    print(\"\\n\".join(log_path.read_text(encoding=\"utf-8\").splitlines()[-40:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893b1c33",
   "metadata": {},
   "source": [
    "## 9) Salvataggio artefatti su Drive (modelli, report, zip)\n",
    "Se Drive è montato, copia l’ultima cartella di risultati e/o crea uno ZIP in Drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8aa9deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "if not latest:\n",
    "    print(\"Nessun run da copiare\")\n",
    "elif not MOUNT_DRIVE:\n",
    "    print(\"Drive non montato: setta MOUNT_DRIVE=True nella sezione 4\")\n",
    "else:\n",
    "    dest = DRIVE_OUT_DIR / latest.name\n",
    "    if dest.exists():\n",
    "        shutil.rmtree(dest)\n",
    "    shutil.copytree(latest, dest)\n",
    "    print(\"Copied to:\", dest)\n",
    "\n",
    "    zip_in_drive = DRIVE_OUT_DIR / f\"{latest.name}.zip\"\n",
    "    if zip_in_drive.exists():\n",
    "        zip_in_drive.unlink()\n",
    "\n",
    "    shutil.make_archive(str(zip_in_drive).replace(\".zip\", \"\"), \"zip\", root_dir=latest)\n",
    "    print(\"ZIP in Drive:\", zip_in_drive, f\"({zip_in_drive.stat().st_size} bytes)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ecafff",
   "metadata": {},
   "source": [
    "## 10) Download risultati su locale\n",
    "Crea uno ZIP dell’ultima cartella e scaricalo sul tuo PC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8d3654",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "if not latest:\n",
    "    raise RuntimeError(\"Nessun run trovato\")\n",
    "\n",
    "zip_path = pathlib.Path(\"/content\") / f\"{latest.name}.zip\"\n",
    "if zip_path.exists():\n",
    "    zip_path.unlink()\n",
    "\n",
    "shutil.make_archive(str(zip_path).replace(\".zip\", \"\"), \"zip\", root_dir=latest)\n",
    "print(\"Created:\", zip_path, f\"({zip_path.stat().st_size} bytes)\")\n",
    "\n",
    "files.download(str(zip_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e1f937",
   "metadata": {},
   "source": [
    "## 11) Test rapidi / smoke test\n",
    "Esegui un run ultrarapido per verificare che import/dataset/model funzionino (utile prima di lanciare run lunghi)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950b32b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smoke test: 2 esempi, pochi token, niente perturb\n",
    "smoke_cmd = [\n",
    "    \"python\", \"run_experiment.py\",\n",
    "    \"--dataset\", CFG[\"dataset\"],\n",
    "    \"--split\", CFG[\"split\"],\n",
    "    \"--n\", \"2\",\n",
    "    \"--seed\", str(CFG[\"seed\"]),\n",
    "    \"--model\", CFG[\"model\"],\n",
    "    \"--prompt\", CFG[\"prompt\"],\n",
    "    \"--max-new-tokens\", \"64\",\n",
    "    \"--no-perturb\",\n",
    "    \"--streaming\",\n",
    "    \"--streaming-buffer-size\", \"2000\",\n",
    "    \"--output\", \"results_smoke.json\",\n",
    "]\n",
    "print(\"Smoke:\", \" \".join(smoke_cmd))\n",
    "\n",
    "rc = subprocess.call(smoke_cmd)\n",
    "print(\"Exit code:\", rc)\n",
    "if rc != 0:\n",
    "    raise RuntimeError(\"Smoke test failed\")\n",
    "\n",
    "latest_smoke = latest_analysis_dir(OUT_DIR)\n",
    "print(\"Latest after smoke:\", latest_smoke)\n",
    "if latest_smoke:\n",
    "    print(\"REPORT:\", latest_smoke / \"REPORT.md\")\n",
    "    print(\"JSON:\", latest_smoke / \"results_smoke.json\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
