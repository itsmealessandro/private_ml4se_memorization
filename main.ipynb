{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6030d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6da8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "from datasets import load_dataset\n",
    "\n",
    "from models.model_wrappers import LocalLLM\n",
    "from evaluation.metrics import is_memorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e51e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_SIZE = 2000  # sicuro per PC portatile\n",
    "\n",
    "dataset = load_dataset(\n",
    "    \"code_search_net\",\n",
    "    \"python\",\n",
    "    split=\"train\"\n",
    ")\n",
    "\n",
    "dataset = dataset.shuffle(seed=42).select(range(DATASET_SIZE))\n",
    "\n",
    "data = [{\n",
    "    \"function_name\": x[\"func_name\"],\n",
    "    \"docstring\": x[\"docstring\"],\n",
    "    \"code\": x[\"code\"]\n",
    "} for x in dataset]\n",
    "\n",
    "print(f\"Loaded {len(data)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8024b4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"prompts/function_prompt.txt\") as f:\n",
    "    FUNCTION_PROMPT = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9501a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LocalLLM(\n",
    "    \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a35eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "memorized = 0\n",
    "results = []\n",
    "\n",
    "for sample in tqdm(data):\n",
    "    prompt = FUNCTION_PROMPT.replace(\n",
    "        \"{FUNCTION_NAME}\", sample[\"function_name\"]\n",
    "    )\n",
    "\n",
    "    output = model.generate(prompt)\n",
    "\n",
    "    hit = is_memorized(\n",
    "        pred=output,\n",
    "        gold=sample[\"docstring\"]\n",
    "    )\n",
    "\n",
    "    results.append({\n",
    "        \"function_name\": sample[\"function_name\"],\n",
    "        \"memorized\": hit\n",
    "    })\n",
    "\n",
    "    if hit:\n",
    "        memorized += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686cbd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "coverage = memorized / len(data)\n",
    "print(f\"Memorization Coverage: {coverage:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f51224",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"results.json\", \"w\") as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "print(\"Results saved to results.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d080135",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random_hits = sum(random.choice([True, False]) for _ in range(len(data)))\n",
    "print(\"Random baseline coverage:\", random_hits / len(data))"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
